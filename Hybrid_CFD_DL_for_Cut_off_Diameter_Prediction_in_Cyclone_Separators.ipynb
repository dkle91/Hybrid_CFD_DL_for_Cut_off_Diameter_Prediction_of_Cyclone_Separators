{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxR6vNfapSh3"
      },
      "outputs": [],
      "source": [
        "#Import TensorFlow and NumPy\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import sys\n",
        "sys.path.insert(0, 'drive/content/')\n",
        "import scipy.io\n",
        "from keras import models \n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from google.colab import files\n",
        "\n",
        "# demonstrate data normalization with sklearn\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Set data type\n",
        "DTYPE='float32'\n",
        "tf.keras.backend.set_floatx(DTYPE)\n",
        "# Load data\n",
        "data = np.empty([201,5], dtype=DTYPE)\n",
        "data = np.loadtxt('Input_data.csv',delimiter=',')\n",
        "shuffle_data = shuffle(data)\n",
        "ratio = shuffle_data[:,3]/shuffle_data[:,4]\n",
        "\n",
        "\n",
        "# 1. Activation function: 0-tanh, 1-sigmoid, 2-Relu\n",
        "activation = 'tanh'\n",
        "# 2. Optimizer: 0-Adam, 1-SGD, 2-RMSprop\n",
        "optimizer = 'SGD'\n",
        "# 3. Learning rate: 0-1e-2, 1-1e-3, 2-1e-4\n",
        "learn_rate = 5e-2\n",
        "# 4. Number of epochs: 0-2500, 1-5000, 2-7500\n",
        "N_epoch = 5000\n",
        "# 5. Number of neurons: 0-10, 1-20, 2-30\n",
        "num_neurons_per_layer =  50\n",
        "# 6. Number of layers: 0-6, 1-8, 2-10\n",
        "num_hidden_layers = 1\n",
        "# 7. Batch size\n",
        "batch = 1\n",
        "\n",
        "#Normalize the data\n",
        "# create scaler\n",
        "scaler = MinMaxScaler()\n",
        "# fit scaler on data\n",
        "scaler.fit(shuffle_data)\n",
        "# apply transform\n",
        "normalized_data = scaler.transform(shuffle_data)\n",
        "# Prepare train & test data\n",
        "x_train = tf.convert_to_tensor(normalized_data[:161,:3], dtype=DTYPE)\n",
        "y_train = tf.convert_to_tensor(ratio[:161], dtype=DTYPE)\n",
        "x_val = tf.convert_to_tensor(normalized_data[161:181,:3], dtype=DTYPE)\n",
        "y_val = tf.convert_to_tensor(ratio[161:181], dtype=DTYPE)\n",
        "\n",
        "#5-fold cross validation\n",
        "\n",
        "x_test = tf.convert_to_tensor(normalized_data[181:,:3], dtype=DTYPE)\n",
        "y_test = tf.convert_to_tensor(ratio[181:], dtype=DTYPE)\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "    # Input is two-dimensional (time + one spatial dimension)\n",
        "model.add(tf.keras.Input(3))\n",
        "\n",
        "    # Append hidden layers\n",
        "for _ in range(num_hidden_layers):\n",
        "    model.add(tf.keras.layers.Dense(num_neurons_per_layer,\n",
        "        activation=tf.keras.activations.get(activation),\n",
        "        kernel_initializer='uniform'))\n",
        "\n",
        "    # Output is one-dimensional\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "if optimizer==\"Adam\":\n",
        "  optimizer_op = tf.keras.optimizers.Adam(learning_rate=learn_rate)\n",
        "if optimizer==\"SGD\":\n",
        "  optimizer_op = tf.keras.optimizers.SGD(learning_rate=learn_rate)\n",
        "if optimizer==\"RMSprop\":\n",
        "  optimizer_op = tf.keras.optimizers.RMSprop(learning_rate=learn_rate)\n",
        "\n",
        "model.compile(loss='mse', optimizer= optimizer_op, metrics=['accuracy'])\n",
        "\n",
        "#log_dir=\".logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "training_history = model.fit(\n",
        "    x_train,\n",
        "    y_train, \n",
        "    validation_data=(x_val, y_val),\n",
        "    epochs= N_epoch, batch_size = batch,  verbose=2)\n",
        "\n",
        "# summarize history for loss\n",
        "plt.figure(figsize=(18,12))\n",
        "plt.plot(training_history.history['loss'])\n",
        "plt.plot(training_history.history['val_loss'])\n",
        "#plt.title('Loss', fontsize=20)\n",
        "plt.ylabel('Loss', fontsize=20)\n",
        "plt.xlabel('Epoch', fontsize=20)\n",
        "plt.xticks(fontsize=16, rotation=0)\n",
        "plt.yticks(fontsize=16, rotation=0)\n",
        "plt.legend(['Train', 'Validate'], loc='upper right', fontsize=20)\n",
        "plt.savefig('Loss graph.jpeg', bbox_inches='tight', dpi=600);\n",
        "plt.show()\n",
        "\n",
        "# create scaler\n",
        "scaler1 = MinMaxScaler()\n",
        "# fit scaler on data\n",
        "all = data[:,:3]\n",
        "scaler1.fit(all)\n",
        "# apply transform\n",
        "normalized_all = scaler1.transform(all)\n",
        "all_test = tf.convert_to_tensor(normalized_all, dtype=DTYPE)\n",
        "test_all = model.predict(all_test)\n",
        "test_all\n",
        "np.savetxt('Hyrbrid results.csv', test_all)\n",
        "\n",
        "# Predict for all dataset\n",
        "predict_test = model.predict(x_test)\n",
        "exact_test = y_test.numpy()\n",
        "exact_test = exact_test.reshape(-1,1)\n",
        "predict_train = model.predict(x_train)\n",
        "exact_train = y_train.numpy()\n",
        "exact_train = exact_train.reshape(-1,1)\n",
        "predict_val = model.predict(x_val)\n",
        "exact_val = y_val.numpy()\n",
        "exact_val = y_val.numpy()\n",
        "\n",
        "#Evaluate the errors\n",
        "#Train error\n",
        "exact_train = y_train.numpy()\n",
        "exact_train = exact_train.reshape(-1,1)\n",
        "error_train = np.absolute(predict_train - exact_train)*100/exact_train\n",
        "print('The mean train error is: ', np.average(error_train))\n",
        "#Validate error\n",
        "exact_val = y_val.numpy()\n",
        "exact_val = exact_val.reshape(-1,1)\n",
        "error_val = np.absolute(predict_val - exact_val)*100/exact_val\n",
        "print('The mean validation error is: ', np.average(error_val))\n",
        "#Test error\n",
        "exact_test = y_test.numpy()\n",
        "exact_test = exact_test.reshape(-1,1)\n",
        "error_test = np.absolute(predict_test - exact_test)*100/exact_test\n",
        "print('The mean test error is: ', np.average(error_test))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
